{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs into the python environment. These functions will be referenced later in the notebook code.\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from IPython.display import Markdown, display\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D  # <-- Note the capitalization!\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# Modules from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether the movie or the TV show is going to be nominated or win an award\n",
    "\n",
    "Assuming the role of lead data scientist in 2005, you're presented with a challenge: Amazon Studios wants to produce award-winning films and, therefore, focus the budget on projects with the best chance of winning those awards. Using the actual dataset from IMDb, an Amazon subsidiary, you begin your investigation by looking for movies made between 1990 and 2005.\n",
    "\n",
    "The IMDb dataset is a feature-rich, comprehensive listing of all films released during that time period; it includes critical data such as cast and crew, synopsis, and other production data. Much of this data is published on the public IMDb.com site, while other features are embargoed for studio analytics.\n",
    "\n",
    "Your task is to predict which movies will most likely be nominated for an award during the upcoming 2005 awards season by building an awards analysis prediction model. \n",
    "\n",
    "This is a notebook in which we read in fields of data from the IMDB database and build a model to make predictions of whether the movie is \"nominated\" or \"Winner\".\n",
    "\n",
    "This data set is being provided to you by permission of IMDb and is subject to the terms of the AWS Digital Training Agreement (available at https://aws.amazon.com/training/digital-training-agreement).  You are expressly prohibited from copying, modifying, selling, exporting or using this data set in any way other than for the purpose of completing this lab.\n",
    "\n",
    "## Importing the required libraries \n",
    "\n",
    "For this exercise, you will use the scikit-learn library to preprocess the models and make predictions. \n",
    "(You can add any other libraries that you need below as well.)\n",
    "\n",
    "# Importing libs into the python environment. These functions will be referenced later in the notebook code.\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from IPython.display import Markdown, display\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D  # <-- Note the capitalization!\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# Modules from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "## Thinking about your Data\n",
    "\n",
    "The IMDB database contains a huge amount of information, so it's important to consider what kinds of information are relevant to your prediction. Here's the schema you're using.\n",
    "\n",
    "\n",
    "<img src=\"Data-Schema-Capstone.png\">\n",
    "\n",
    "## Cleaning and Visualizing Your Data\n",
    "\n",
    "Replace **<LabBucketName\\>** with the resource name that was provided with your lab account.\n",
    "\n",
    "import boto3\n",
    "import botocore \n",
    "bucket = 'mlu-data-109836276268-us-west-2-qls-11926192-632c22f599f6ad0c' # Update this to the bucket that was created in your lab account as part of this enviroment.\n",
    "prefix = 'data/'\n",
    " \n",
    "s3 = boto3.resource('s3') \n",
    "\n",
    "\n",
    "Raw data files are in an S3 bucket in your AWS lab account. Six tables will be used (`title_genres`, `title_ratings`, `title_display`, `award_noms`, `title_awards`, `title_releases`). Raw tab-separated value files will be downloaded into your Amazon Sagemaker instance, and imported into a DataFrame, where it's easier to work  with the structured data. Raw files do not contain row headers, and thus labels are being assiged at import.\n",
    "\n",
    "def download_and_display_file(filename,names, title):\n",
    "    s3.Bucket(bucket).download_file(filename, filename)\n",
    "    user_info = pd.read_csv(filename, sep='\\t', encoding= 'latin1', names = names)\n",
    "    display(Markdown(\"**\" + title +\" Table** \\n\"))\n",
    "    display(user_info.head(5))\n",
    "    return user_info\n",
    "\n",
    "user_info_genres = download_and_display_file('title_genres.tsv', ['titleId','genres'], 'Genres')\n",
    "user_info_ratings = download_and_display_file('title_ratings.tsv', [\"titleId\",\"rating\",\"ratingCount\",\"topRank\",\"bottomRank\",\"topRankTV\"], 'Rating')\n",
    "user_info_display = download_and_display_file('title_display.tsv', [\"titleId\",\"title\",\"year\",\"adult\",\"runtimeMinutes\",\"imageUri\",\"imageId\",\"type\",\"originalTitle\"], 'Display')\n",
    "user_info_noms = download_and_display_file('award_noms.tsv', [\"awardId\",\"eventId\",\"event\",\"eventEditionId\",\"award\",\"category\",\"year\"], 'Nomination')\n",
    "user_info_awards = download_and_display_file('title_awards.tsv', [\"titleId\",\"awardId\",\"winner\"], 'Awards')\n",
    "user_info_releases = download_and_display_file('title_releases.tsv', [\"titleId\",\"ordering\",\"date\",\"region\",\"premiere\",\"wide\",\"premiereType\",\"festival\",\"attributes\"], 'Releases')\n",
    "\n",
    "\n",
    "\n",
    "The data in table format (.tsv) are consumed into a Pandas DataFrame for data preprocessing. The data is split between six different files or DataFrames. Merge the data to obtain a unified DataFrame which will be used to do further data exploration, data engineering, visualization, and model building. You will use the built-in `merge` function in pandas to merge the DataFrames together. `TitleId` is a uniqueId that is assigned to each movie title in this dataset. A set of inner joins between `title_ratings`, `title_genres`, `title_display`, `title_releases` will merge all these tables together. \n",
    "\n",
    "df_first_merge = pd.merge(user_info_genres, user_info_ratings, on='titleId', how='inner')\n",
    "df_second_merge = pd.merge(df_first_merge, user_info_display, on='titleId', how='inner')\n",
    "df_third_merge = pd.merge(df_second_merge, user_info_releases, on='titleId', how='inner')\n",
    "\n",
    "Duplicate titleId is dropped, prior to doing a outer join with (title_awards) table. The resulted duplicates in the DataFrame are dropped, as well as a few of the data columns. The IMDB dataset is huge with hundreds of fields - only the relevant fields are picked here that could possibly affect the model output.  After reading in these relevant tables, only the relevant fields are retained and the rest of them are dropped as shown below.\n",
    "\n",
    "df_third_merge = df_third_merge.drop_duplicates(['titleId'])\n",
    "df_fourth_merge = pd.merge(df_third_merge,user_info_awards,on='titleId', how='outer' )\n",
    "    \n",
    "df = df_fourth_merge.drop_duplicates(['titleId'])\n",
    "df = df.drop(['imageUri','topRank','bottomRank','topRankTV','ordering','premiereType','festival' ], axis=1)\n",
    "\n",
    "The resulted DataFrame is serialized and written to a flat file called the Pickle using the **Pickle** library. This file is then saved into the Amazon S3 bucket for later re-use of the data. You can generate a Pickle file using `pickle.dump` and save the raw datafile in that object and upload the file to the lab S3 bucket.\n",
    "\n",
    "with open('df_pickle_nonoms_new.pkl', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "s3.Bucket(bucket).upload_file('df_pickle_nonoms_new.pkl','data/df_pickle_nonoms_new.pkl')\n",
    "\n",
    "Review the top 30 rows of optimized table.\n",
    "\n",
    "df.head(30)\n",
    "\n",
    "Run some basic pandas descriptive statistics on your new DataFrame. \n",
    "\n",
    "`df.info()` prints more information about your DataFrame. This includes information such as index dtype, column dtypes, non-null values and memory usage. `df.describe()` generates descriptive statistics such as mean, median, mode etc.\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "Load the Pickle file into a Pandas Dataframe and drop some of the irrelevant features.\n",
    "\n",
    "s3.Bucket(bucket).download_file('data/df_pickle_nonoms_new.pkl', 'df_pickle_nonoms_new.pkl')\n",
    "df = pickle.load(open('df_pickle_nonoms_new.pkl', 'rb'))\n",
    "df = df[df.type == 'movie']\n",
    "df = df.drop(['imageId', 'originalTitle', 'awardId', 'attributes' ], axis=1)\n",
    "\n",
    "The resulted data requires normalization. The source data has `\\N` as the value if the run time of a movie is not known. This null value will cause issues when trying to plot the data. You will change any `\\N` for runtime to a zero. \n",
    "\n",
    "Similarly, if the film released year is not known, value is set to `\\N`. You will change any `\\N` for year to a zero in the cell below.\n",
    "\n",
    "Below will display tables with runtimeMinutes `\\N`.\n",
    "\n",
    "# display full coloum width\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df[df.runtimeMinutes == r'\\N'].head()\n",
    "\n",
    "Below will display tables with year `\\N`.\n",
    "\n",
    "df[df.year == r'\\N'].head()\n",
    "\n",
    "for i, mins in df['runtimeMinutes'].iteritems():\n",
    "    if mins == r'\\N':\n",
    "        better_name = '0'\n",
    "        df.loc[[i],['runtimeMinutes']] = better_name\n",
    "\n",
    "for i, year in df['year'].iteritems():\n",
    "    if year == r'\\N':\n",
    "        better_name = '0'\n",
    "        df.loc[[i],['year']] = better_name\n",
    "\n",
    "\n",
    "A separate column called `nomination_winner` is added to the DataFrame. If winner column has either `0.0` or `1.0` value, it is assumed that the title has been nominated. Else, the title has not been nominated.\n",
    "\n",
    "df['nomination_winner'] = 0\n",
    "for i, winner in df['winner'].iteritems():\n",
    "    if winner == (0.0):\n",
    "        better_name = 1\n",
    "        df.loc[[i],['nomination_winner']] = better_name\n",
    "    if winner == (1.0):\n",
    "        better_name = 1\n",
    "        df.loc[[i],['nomination_winner']] = better_name\n",
    "\n",
    " You will also use the `fillna` function to fill the missing values in the `year` column and `runtimeMinutes` column.\n",
    "\n",
    "df.runtimeMinutes = df.runtimeMinutes.astype(float).fillna(0.0)\n",
    "df.year = df.year.astype(int).fillna(0.0)\n",
    "\n",
    "Some titles that are included into your dataset have run times that don't seem to fit. You are going to limit this data with a runtime of longer then 1 hour (60 minutes) and no greater then 12 hours (720 minutes). YOU are also going to focus on movies with a `reviewCount` of less than 20,000.\n",
    "\n",
    "Below, you will see sample data with `runtimesMinutes` of less than 60 minutes.\n",
    "\n",
    "df[(df.runtimeMinutes) < 60].head()\n",
    "\n",
    "Below, you will see sample data with `runtimesMinutes` of more than 720 minutes.\n",
    "\n",
    "df[(df.runtimeMinutes) > 720].head()\n",
    "\n",
    "df = df[(df.runtimeMinutes) > 60]\n",
    "df = df[(df.runtimeMinutes) < 720]\n",
    "df = df[(df.ratingCount) < 20000]\n",
    "\n",
    "**Review top 30 columns of optimized data.**\n",
    "\n",
    "df.head(30)\n",
    "\n",
    "print('='*50)\n",
    "df.info()\n",
    "print('='*50)\n",
    "df.describe()\n",
    "\n",
    "**Below, you are saving dataframe for year 2005 as df_2005 for future use.**\n",
    "\n",
    "df_2005 = df[(df.year) == 2005]\n",
    "df_2005.head()\n",
    "\n",
    "## Feature Selection and Feature Engineering\n",
    "<a id='feature selection'></a>\n",
    "\n",
    "**Feature Selection Box:** The toggle switches for various features and settings are below. A value of 0 disables the feature, and a value of 1 enables the feature.\n",
    "\n",
    "# Selection of different features\n",
    "\n",
    "feature_winner = 0          # Select this feature to make prediction on award winner. \n",
    "                            # Disable this feautre to make prediction on nomination winners.\n",
    "    \n",
    "feature_pca_2D = 0          # Select this feature to perform Principal Component Analysis of 2 components.\n",
    "feature_pca_3D = 1          # Select this feature to perform Principal Component Analysis of 3 components.\n",
    "\n",
    "feature_premiere = 0        # Select this feature to limit analysis on limited premiered movies.\n",
    "feature_wide = 0            # Select this feature to limit analysis on world wide premiered movies.\n",
    "feature_premiere_wide = 1   # Select this feature to include analysis on both limited and wide premiered movies.\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "normalize_flag = 0\n",
    "\n",
    "#Enable plotting\n",
    "plot_flag = 1                 \n",
    "\n",
    "#Feaure Selection \n",
    "US_flag = 1                 # Select this feature to limit analysis on US based movies.\n",
    "\n",
    "#Model Selection flags\n",
    "LR_flag = 1\n",
    "DT_flag = 1\n",
    "RF_flag = 1\n",
    "GB_flag = 1\n",
    "NN_flag = 1\n",
    "SVM_flag = 1\n",
    "\n",
    "\n",
    "**Clean up and constrain the data:** \n",
    "- Explore by limiting your dta to only **US** features. \n",
    "- Explore by choosing whether to use **nomination** or **winner** to be output target.\n",
    "\n",
    "if plot_flag: \n",
    "    prob = df.region.value_counts(normalize=True)\n",
    "    threshold = 0.02\n",
    "    mask = prob > threshold\n",
    "    tail_prob = prob.loc[~mask].sum()\n",
    "    prob = prob.loc[mask]\n",
    "    prob['other'] = tail_prob\n",
    "    prob.plot(kind='bar')\n",
    "    plt.xticks(rotation=25)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "if US_flag:\n",
    "    df = df[ (df.region) == 'US']\n",
    "\n",
    "\n",
    "# This flag is set if \"winner\" is chosen as output label\n",
    "\n",
    "if feature_winner:\n",
    "    df = df[(df.nomination_winner) == 1]\n",
    "\n",
    "    for i, winner in df['winner'].iteritems():\n",
    "        if winner == (0.0):\n",
    "            better_name = 0\n",
    "            df.loc[[i],['nomination_winner']] = better_name\n",
    "        if winner == (1.0):\n",
    "            better_name = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You are going to be graphing the features to help better understand how features might relate to each other. Below is defining the function to be called later after the data has been imported. \n",
    "\n",
    "#plot Confusion Matrix function\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# end Confusion Matrix function\n",
    "\n",
    "\n",
    "# ROC Curve Plotting function\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',\n",
    "             label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([-0.1, 1.2])\n",
    "    plt.ylim([-0.1, 1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#end ROC plotting function\n",
    "\n",
    "\n",
    "# Precision Recall (PR) function\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show( )\n",
    "    plt.close()\n",
    "\n",
    "#end PR function\n",
    " \n",
    "\n",
    "Below you will plot histograms of different features such as `rating`, `ratingCount`. Review the effect of `premier` flag on the output. Also look at the effects or cross correlation between the different features as well as the output.  You see that the `ratingCount` has the maximum effect on the output `nomination_winner` (could be `nomination` or `winner`). \n",
    "\n",
    "\n",
    "# Plot rating vs rating count & Histogram of Rating\n",
    "\n",
    "if plot_flag:\n",
    "    \n",
    "    df['rating'].hist()\n",
    "    plt.title('Histogram of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    df_plot = df[(df.ratingCount) < 10000]\n",
    "    df_plot['ratingCount'].hist(bins=100)\n",
    "    plt.title('Histogram of Rating Count')\n",
    "    plt.xlabel('Rating Count')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plot_hist1 = df[(df.nomination_winner) == 1]\n",
    "    plot_hist0 = df[(df.nomination_winner) == 0]\n",
    "    plt.hist(df.nomination_winner)\n",
    "    plt.hist(plot_hist1.premiere)\n",
    "    plt.xlabel('Nomination/Premiere')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    " \n",
    "    #Plotting correlation  \n",
    "\n",
    "    \n",
    "    sns.pairplot(df[['nomination_winner', 'ratingCount','rating', 'runtimeMinutes' ]].head(5000));\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "**Experiment with different features and look at the roc scores in each model.** Run steps through **Feature Selection Box.**\n",
    "\n",
    "<a href='#feature selection'>**Link to the feature selection box**</a>\n",
    "\n",
    "\n",
    "if feature_premiere_wide:\n",
    "    X_train = df[['rating', 'ratingCount', 'runtimeMinutes','premiere','wide']]\n",
    "elif feature_premiere:\n",
    "    X_train = df[['rating', 'ratingCount', 'runtimeMinutes','premiere' ]]\n",
    "elif feature_wide:\n",
    "    X_train = df[['rating', 'ratingCount',  'runtimeMinutes' ,'wide']]\n",
    "else :\n",
    "    X_train = df[['rating', 'ratingCount',  'runtimeMinutes']]\n",
    "\n",
    "\n",
    "Y_train = df['nomination_winner']\n",
    "\n",
    "if normalize_flag:\n",
    "    X_train=(StandardScaler().fit_transform(X_train ))\n",
    "\n",
    "\n",
    "Below you will Experiment with **Principal Component Analysis** and reduce the Feature set to three main components.\n",
    "\n",
    "#PCA\n",
    "\n",
    "\n",
    "if feature_pca_3D:\n",
    "    pca = decomposition.PCA(n_components=3)\n",
    "    \n",
    "     \n",
    "    principalComponents = pca.fit_transform(X_train )\n",
    "\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2','principal component 3'])\n",
    "    \n",
    "    \n",
    "    finalDf = pd.concat([principalDf, Y_train], axis = 1)\n",
    "    finalDf = finalDf.head(2000)\n",
    "    targets = [1, 0 ]\n",
    "    colors = ['r', 'g' ]\n",
    "     \n",
    "    my_dpi = 96\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    \n",
    "    ax = fig.add_subplot(111,projection='3d' )\n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 8)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 8)\n",
    "    ax.set_zlabel('Principal Component 3', fontsize = 8)\n",
    "    ax.set_title('3 component PCA', fontsize = 15)\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['nomination_winner'] == target\n",
    "        \n",
    "        \n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "                    , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "                   ,  finalDf.loc[indicesToKeep, 'principal component 3']\n",
    "                    , c = color,  linewidth=0.5)\n",
    "        \n",
    "    ax.legend(targets)\n",
    "    #ax.grid() \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    \n",
    "    # In order to use PCA_3D for testing, uncomment below line and run this cell.\n",
    "    #X_train = X_train_pca \n",
    "    \n",
    "elif feature_pca_2D:\n",
    "    \n",
    "     \n",
    "    pca = decomposition.PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(X_train )\n",
    "\n",
    "    \n",
    "    \n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2'] )\n",
    "    \n",
    "    finalDf = pd.concat([principalDf, Y_train], axis = 1)\n",
    "    finalDf = finalDf.head(50)\n",
    "    \n",
    "    targets = [1, 0 ]\n",
    "    colors = ['r', 'g' ]\n",
    "     \n",
    "    my_dpi = 96\n",
    "  \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111 )\n",
    "\n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 8)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 8)\n",
    "\n",
    "    ax.set_title('2 component PCA', fontsize = 15)\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['nomination_winner'] == target\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "                   , finalDf.loc[indicesToKeep, 'principal component 2']               \n",
    "                    , c = color,  linewidth=0.5)\n",
    "\n",
    "    ax.legend(targets)\n",
    "    #ax.grid() \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    \n",
    "    # In order to use PCA_2D for testing, uncomment below line and run this cell.\n",
    "    #X_train = X_train_pca \n",
    "    \n",
    "  \n",
    "\n",
    "#PCA ends\n",
    "\n",
    "You will notice during the analysis that the \"nomination/winner\" 3D points (Red dots) are within the clusters of the non \"nomination/winner\" 3D points (Green dots). This suggests it is hard to classify your data in 3D model using PCA analysis.\n",
    "\n",
    "Split the dataset into training and test data sets.\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=0)\n",
    " \n",
    "\n",
    "## Algorithm Comparison and Selection\n",
    "\n",
    "Now you will build models using Logistic Regression, Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), Gradient Boosting (GB) and Multi-Layer Perceptron (NN) classification schemes. The various scores such as Precision, Recall, ROC, F1, Accuracy are measured. You will also plot the ROC curves for the different models. \n",
    "\n",
    "if LR_flag:\n",
    "\n",
    "# Logistic Regression Model\n",
    "\n",
    "    logisticRegr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                        multi_class='multinomial', max_iter=1000)\n",
    "    logisticRegr.fit(x_train, y_train)\n",
    "    y_test_pred_LR = cross_val_predict(logisticRegr, x_test, y_test, cv=3)\n",
    "    score = logisticRegr.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_LR\n",
    "    print(\"LR Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    LR_CR = classification_report(y_test, y_test_pred)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute ROC curve and ROC area\n",
    "    #fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "  \n",
    "\n",
    "    \n",
    "    logit_roc_auc = roc_auc_score(y_test_pred, logisticRegr.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, logisticRegr.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression ' )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if SVM_flag:\n",
    "    # SVM Model\n",
    "\n",
    "    sgd_clf = SGDClassifier(random_state=0, loss=\"log\", max_iter=1000, tol=3 )\n",
    "    sgd_clf.fit(x_train, y_train)\n",
    "    cross_val_score(sgd_clf, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_SVC = cross_val_predict(sgd_clf, x_test, y_test, cv=3)\n",
    "    predictions = sgd_clf.predict(x_test)\n",
    "    score = sgd_clf.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_SVC\n",
    "    print(\"SVM Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred_SVC)\n",
    "    print(\"roc score\", roc)\n",
    "    SVM_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(SVM_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "     \n",
    "  \n",
    "    \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, sgd_clf.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, sgd_clf.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='SVM  ' )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if DT_flag:\n",
    "    # Decision Tree Model\n",
    "\n",
    "    DT = DecisionTreeClassifier(random_state=42)\n",
    "    DT.fit(x_train, y_train)\n",
    "    cross_val_score(DT, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_DT = cross_val_predict(DT, x_test, y_test, cv=3)\n",
    "    predictions = DT.predict(x_test)\n",
    "    score = DT.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_DT\n",
    "    print(\"DT Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    DT_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(DT_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "    \n",
    " \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, DT.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, DT.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Decision Tree '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if RF_flag:\n",
    "    # Ensemble Random Forest Model\n",
    "\n",
    "    RF = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    RF.fit(x_train, y_train)\n",
    "    cross_val_score(RF, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_RF = cross_val_predict(RF, x_test, y_test, cv=3)\n",
    "    predictions = RF.predict(x_test)\n",
    "    score = RF.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_RF\n",
    "    print(\"RF Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    RF_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(RF_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "    roc_auc = roc_auc_score(y_test_pred, sgd_clf.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, sgd_clf.predict_proba(x_test)[:,1])\n",
    " \n",
    "    \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, RF.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, RF.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Random Forest ' )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if GB_flag:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(x_train, y_train)\n",
    "\n",
    "    cross_val_score(gb_clf, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_gb = cross_val_predict(gb_clf, x_test, y_test, cv=3)\n",
    "    predictions = gb_clf.predict(x_test)\n",
    "    score = gb_clf.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_gb\n",
    "    print(\"GB Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    GB_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(GB_CR)\n",
    "    \n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "    roc_auc  = auc(fpr , tpr )\n",
    " \n",
    " \n",
    "    roc_auc = roc_auc_score(y_test_pred, gb_clf.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, gb_clf.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Gradient Boosting  '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if NN_flag:\n",
    "\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(20, 20, 20), max_iter=1000)\n",
    "    mlp.fit(x_test, y_test)\n",
    "\n",
    "    cross_val_score(mlp, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "    y_test_pred_NN = cross_val_predict(mlp, x_test, y_test, cv=3)\n",
    "    predictions = mlp.predict(x_test)\n",
    "    score = mlp.score(x_test, y_test)\n",
    "\n",
    "    y_test_pred = y_test_pred_NN\n",
    "    print(\"NN Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    NN_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(NN_CR)\n",
    "    \n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "    roc_auc  = auc(fpr , tpr )\n",
    "  \n",
    " \n",
    "    \n",
    "     \n",
    "    roc_auc = roc_auc_score(y_test_pred, mlp.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, mlp.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='MLP  '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "\n",
    "Below will display classification report of respective models.\n",
    "\n",
    "report_list = [LR_CR,SVM_CR,DT_CR,RF_CR,GB_CR,NN_CR]\n",
    "model_list = ['LR','SVM','DT','RF','GB','NN']\n",
    "def display_report(model,report):\n",
    "    display(Markdown(model+\" **Model Classification Report** \\n\"))\n",
    "    print('\\n',report)\n",
    "    \n",
    "for (model,report) in zip(model_list, report_list):\n",
    "    display_report(model,report)\n",
    "  \n",
    "\n",
    "# Question\n",
    "Based on **Precision, Recall and F1 metrics**, which **model** do you think best fit our prediction?\n",
    "\n",
    "**Now run 2005 data against your identified model.**\n",
    "\n",
    "# Model Test\n",
    "\n",
    "Run below code to review **2005 data.**\n",
    "\n",
    "df_2005.head(30)\n",
    "\n",
    "Select X_train and Y_train data based on selected feature in feature selection box. You can review your selection by clicking below link.\n",
    "\n",
    "<a href='#feature selection'>**Link to the feature selection box**</a>\n",
    "\n",
    "if feature_premiere_wide:\n",
    "    X_train = df_2005[['rating', 'ratingCount', 'runtimeMinutes','premiere','wide']]\n",
    "elif feature_premiere:\n",
    "    X_train = df_2005[['rating', 'ratingCount', 'runtimeMinutes','premiere' ]]\n",
    "elif feature_wide:\n",
    "    X_train = df_2005[['rating', 'ratingCount',  'runtimeMinutes' ,'wide']]\n",
    "else :\n",
    "    X_train = df_2005[['rating', 'ratingCount',  'runtimeMinutes']]\n",
    "\n",
    "\n",
    "Y_train = df_2005['nomination_winner']\n",
    "\n",
    "if normalize_flag:\n",
    "    X_train=(StandardScaler().fit_transform(X_train ))\n",
    "\n",
    "Split the dataset into training and test data sets.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "**Run the selected model** Copy the code from the best determined model box in the previous step, and paste it into the box below.\n",
    "\n",
    "\n",
    "if DT_flag:\n",
    "    # Decision Tree Model\n",
    "\n",
    "    DT = DecisionTreeClassifier(random_state=42)\n",
    "    DT.fit(x_train, y_train)\n",
    "    cross_val_score(DT, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_DT = cross_val_predict(DT, x_test, y_test, cv=3)\n",
    "    predictions = DT.predict(x_test)\n",
    "    score = DT.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_DT\n",
    "    print(\"DT Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    DT_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(DT_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "    \n",
    " \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, DT.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, DT.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Decision Tree '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"db\": \"BLUDB\",\n",
    "  \"dsn\": \"DATABASE=BLUDB;HOSTNAME=dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net;PORT=50000;PROTOCOL=TCPIP;UID=hpd33015;PWD=423^xqwns3mfwsk6;\",\n",
    "  \"host\": \"dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net\",\n",
    "  \"hostname\": \"dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net\",\n",
    "  \"https_url\": \"https://dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net\",\n",
    "  \"jdbcurl\": \"jdbc:db2://dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net:50000/BLUDB\",\n",
    "  \"parameters\": {},\n",
    "  \"password\": \"423^xqwns3mfwsk6\",\n",
    "  \"port\": 50000,\n",
    "  \"ssldsn\": \"DATABASE=BLUDB;HOSTNAME=dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net;PORT=50001;PROTOCOL=TCPIP;UID=hpd33015;PWD=423^xqwns3mfwsk6;Security=SSL;\",\n",
    "  \"ssljdbcurl\": \"jdbc:db2://dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net:50001/BLUDB:sslConnection=true;\",\n",
    "  \"uri\": \"db2://hpd33015:423%5Exqwns3mfwsk6@dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net:50000/BLUDB\",\n",
    "  \"username\": \"hpd33015\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from EMPLOYEES;\n",
    "select * from DEPARTMENTS;\n",
    "select * from JOBS;\n",
    "select * from JOB_HISTORY;\n",
    "select * from  LOCATIONS;\n",
    "select EMP_ID, F_NAME  from EMPLOYEES where ADDRESS like '%Elgin,IL';\n",
    "select EMP_ID, F_NAME  from EMPLOYEES where B_DATE like '197%';\n",
    "select EMP_ID, F_NAME  from EMPLOYEES where SALARY between 60000 and 70000;\n",
    "select EMP_ID, F_NAME, DEP_ID  from EMPLOYEES order by DEP_ID;\n",
    "select DEP_ID, count (*) as NUM_EMPL from EMPLOYEES group by DEP_ID;\n",
    "select DEP_ID, count (*) as NUM_EMPLOYEES, avg(SALARY) as AVG_SALARY from EMPLOYEES group by DEP_ID;\n",
    "select DEP_ID, count (*) as NUM_EMPLOYEES, avg(SALARY) as AVG_SALARY from EMPLOYEES group by DEP_ID order by AVG_SALARY;\n",
    "select DEP_ID, count (*) as NUM_EMPLOYEES, avg(SALARY) as AVG_SALARY from EMPLOYEES group by DEP_ID \n",
    "having count(*) < 4;\n",
    "select D.DEP_NAME, E.F_NAME, E.L_NAME from EMPLOYEES as E,  DEPARTMENTS as D where E.DEP_ID = D.DEPT_ID_DEP \n",
    "order by D.DEP_NAME, E.L_NAME desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select count(*) from CHICAGO_CRIME_DATA\n",
    "%sql select * from CHICAGO_CRIME_DATA limit 10\n",
    "%sql select count(*) from CHICAGO_CRIME_DATA where ARREST = True\n",
    "%sql select PRIMARY_TYPE, LOCATION_DESCRIPTION from CHICAGO_CRIME_DATA where LOCATION_DESCRIPTION = 'GAS STATION'\n",
    "%sql select COMMUNITY_AREA_NAME from CENCUS_DATA where COMMUNITY_AREA_NAME like 'B%'\n",
    "%sql select NAME_OF_SCHOOL, COMMUNITY_AREA_NUMBER, HEALTHY_SCHOOL_CERTIFIED \\\n",
    "from CHICAGO_PUBLIC_SCHOOLS where (COMMUNITY_AREA_NUMBER between 10 and 15 and HEALTHY_SCHOOL_CERTIFIED = 'Yes')\n",
    "%sql select avg(SAFETY_SCORE) from CHICAGO_PUBLIC_SCHOOLS\n",
    "%sql select COMMUNITY_AREA_NAME, COLLEGE_ENROLLMENT from CHICAGO_PUBLIC_SCHOOLS order by COLLEGE_ENROLLMENT desc limit 5\n",
    "%sql select COMMUNITY_AREA_NAME, SAFETY_SCORE from CHICAGO_PUBLIC_SCHOOLS where SAFETY_SCORE = (select min(SAFETY_SCORE) from CHICAGO_PUBLIC_SCHOOLS)\n",
    "%sql SELECT c.PER_CAPITA_INCOME, c.COMMUNITY_AREA_NAME \\\n",
    "    FROM CENCUS_DATA c, CHICAGO_PUBLIC_SCHOOLS s \\\n",
    "    WHERE s.COMMUNITY_AREA_NUMBER  = c.COMMUNITY_AREA_NUMBER AND s.SAFETY_SCORE = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-99a61d151ea2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-99a61d151ea2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ```js\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "```js\n",
    "// Javascript code with syntax highlighting.\n",
    "var fun = function lang(l) {\n",
    "  dateformat.i18n = require('./lang/' + l)\n",
    "  return true;\n",
    "}\n",
    "```\n",
    "\n",
    "```ruby\n",
    "# Ruby code with syntax highlighting\n",
    "GitHubPages::Dependencies.gems.each do |gem, version|\n",
    "  s.add_dependency(gem, \"= #{version}\")\n",
    "end\n",
    "```\n",
    "\n",
    "#### Header 4\n",
    "\n",
    "*   This is an unordered list following a header.\n",
    "*   This is an unordered list following a header.\n",
    "*   This is an unordered list following a header.\n",
    "\n",
    "##### Header 5\n",
    "\n",
    "1.  This is an ordered list following a header.\n",
    "2.  This is an ordered list following a header.\n",
    "3.  This is an ordered list following a header.\n",
    "\n",
    "###### Header 6\n",
    "\n",
    "| head1        | head two          | three |\n",
    "|:-------------|:------------------|:------|\n",
    "| ok           | good swedish fish | nice  |\n",
    "| out of stock | good and plenty   | nice  |\n",
    "| ok           | good `oreos`      | hmm   |\n",
    "| ok           | good `zoute` drop | yumm  |\n",
    "\n",
    "### There's a horizontal rule below this.\n",
    "\n",
    "* * *\n",
    "\n",
    "### Here is an unordered list:\n",
    "\n",
    "*   Item foo\n",
    "*   Item bar\n",
    "*   Item baz\n",
    "*   Item zip\n",
    "\n",
    "### And an ordered list:\n",
    "\n",
    "1.  Item one\n",
    "1.  Item two\n",
    "1.  Item three\n",
    "1.  Item four\n",
    "\n",
    "### And a nested list:\n",
    "\n",
    "- level 1 item\n",
    "  - level 2 item\n",
    "  - level 2 item\n",
    "    - level 3 item\n",
    "    - level 3 item\n",
    "- level 1 item\n",
    "  - level 2 item\n",
    "  - level 2 item\n",
    "  - level 2 item\n",
    "- level 1 item\n",
    "  - level 2 item\n",
    "  - level 2 item\n",
    "- level 1 item\n",
    "\n",
    "### Small image\n",
    "\n",
    "![Octocat](https://github.githubassets.com/images/icons/emoji/octocat.png)\n",
    "\n",
    "### Large image\n",
    "\n",
    "![Branching](https://guides.github.com/activities/hello-world/branching.png)\n",
    "\n",
    "\n",
    "### Definition lists can be used with HTML syntax.\n",
    "\n",
    "<dl>\n",
    "<dt>Name</dt>\n",
    "<dd>Godzilla</dd>\n",
    "<dt>Born</dt>\n",
    "<dd>1952</dd>\n",
    "<dt>Birthplace</dt>\n",
    "<dd>Japan</dd>\n",
    "<dt>Color</dt>\n",
    "<dd>Green</dd>\n",
    "</dl>\n",
    "\n",
    "```\n",
    "Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this.\n",
    "```\n",
    "\n",
    "```\n",
    "The final element.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/Cho/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - jupyterlab-git\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
      "    conda-4.8.3                |   py37hc8dfbb8_0         3.0 MB  conda-forge\n",
      "    gitdb-4.0.2                |             py_0          46 KB  conda-forge\n",
      "    gitpython-3.1.0            |             py_0         335 KB  conda-forge\n",
      "    jupyterlab-git-0.9.0       |             py_0         145 KB  conda-forge\n",
      "    nbdime-2.0.0               |   py37hc8dfbb8_0         4.6 MB  conda-forge\n",
      "    nodejs-11.14.0             |       h6de7cb9_1        15.4 MB  conda-forge\n",
      "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
      "    smmap-3.0.1                |             py_0          22 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        23.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  gitdb              conda-forge/noarch::gitdb-4.0.2-py_0\n",
      "  gitpython          conda-forge/noarch::gitpython-3.1.0-py_0\n",
      "  jupyterlab-git     conda-forge/noarch::jupyterlab-git-0.9.0-py_0\n",
      "  nbdime             conda-forge/osx-64::nbdime-2.0.0-py37hc8dfbb8_0\n",
      "  nodejs             conda-forge/osx-64::nodejs-11.14.0-h6de7cb9_1\n",
      "  python_abi         conda-forge/osx-64::python_abi-3.7-1_cp37m\n",
      "  smmap              conda-forge/noarch::smmap-3.0.1-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "nbdime-2.0.0         | 4.6 MB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 148 KB    | ##################################### | 100% \n",
      "nodejs-11.14.0       | 15.4 MB   | ##################################### | 100% \n",
      "jupyterlab-git-0.9.0 | 145 KB    | ##################################### | 100% \n",
      "conda-4.8.3          | 3.0 MB    | ##################################### | 100% \n",
      "smmap-3.0.1          | 22 KB     | ##################################### | 100% \n",
      "python_abi-3.7       | 4 KB      | ##################################### | 100% \n",
      "gitdb-4.0.2          | 46 KB     | ##################################### | 100% \n",
      "gitpython-3.1.0      | 335 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge jupyterlab-git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/Cho/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - jupyterlab-git\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.11.28         |           py37_0         153 KB\n",
      "    jupyterlab-git-0.4.4       |             py_0          60 KB  conda-forge/label/cf201901\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         213 KB\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                       conda-forge --> pkgs/main\n",
      "  jupyterlab-git     conda-forge::jupyterlab-git-0.9.0-py_0 --> conda-forge/label/cf201901::jupyterlab-git-0.4.4-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "jupyterlab-git-0.4.4 | 60 KB     | ##################################### | 100% \n",
      "certifi-2019.11.28   | 153 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | b'Disabling: jupyterlab_git\\n- Writing config: /Users/Cho/opt/anaconda3/etc/jupyter\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge/label/cf201901 jupyterlab-git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-6331377fa060>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-6331377fa060>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter labextension install @jupyterlab/github\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter labextension install @jupyterlab/github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5a99dc44ab60>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5a99dc44ab60>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter serverextension enable --sys-prefix jupyterlab_github\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter serverextension enable --sys-prefix jupyterlab_github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-1cde7c885ebd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-1cde7c885ebd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install jupyterlab-git\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install jupyterlab-git\n",
    "jupyter lab build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-6c2e43bd9c6e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-6c2e43bd9c6e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter serverextension enable --py jupyterlab_git\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter serverextension enable --py jupyterlab_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterlab-git\n",
      "  Using cached jupyterlab_git-0.9.0-py3-none-any.whl (144 kB)\n",
      "Requirement already satisfied, skipping upgrade: pexpect in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyterlab-git) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: nbdime>=1.1.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyterlab-git) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyterlab-git) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from pexpect->jupyterlab-git) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2>=2.9 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (2.11.1)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (2.5.2)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: nbformat in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (5.0.4)\n",
      "Requirement already satisfied, skipping upgrade: GitPython!=2.1.4,!=2.1.5,!=2.1.6 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbdime>=1.1.0->jupyterlab-git) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (5.1.4)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.3.4 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (5.3.4)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.2.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook->jupyterlab-git) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jinja2>=2.9->nbdime>=1.1.0->jupyterlab-git) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from requests->nbdime>=1.1.0->jupyterlab-git) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from requests->nbdime>=1.1.0->jupyterlab-git) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from requests->nbdime>=1.1.0->jupyterlab-git) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from requests->nbdime>=1.1.0->jupyterlab-git) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbformat->nbdime>=1.1.0->jupyterlab-git) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from GitPython!=2.1.4,!=2.1.5,!=2.1.6->nbdime>=1.1.0->jupyterlab-git) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook->jupyterlab-git) (7.12.0)\n",
      "Requirement already satisfied, skipping upgrade: appnope; platform_system == \"Darwin\" in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipykernel->notebook->jupyterlab-git) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter-client>=5.3.4->notebook->jupyterlab-git) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook->jupyterlab-git) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook->jupyterlab-git) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook->jupyterlab-git) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook->jupyterlab-git) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook->jupyterlab-git) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook->jupyterlab-git) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2.1->notebook->jupyterlab-git) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbdime>=1.1.0->jupyterlab-git) (46.0.0.post20200309)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbdime>=1.1.0->jupyterlab-git) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbdime>=1.1.0->jupyterlab-git) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbdime>=1.1.0->jupyterlab-git) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=2.1.4,!=2.1.5,!=2.1.6->nbdime>=1.1.0->jupyterlab-git) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook->jupyterlab-git) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook->jupyterlab-git) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook->jupyterlab-git) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook->jupyterlab-git) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->notebook->jupyterlab-git) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->nbdime>=1.1.0->jupyterlab-git) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook->jupyterlab-git) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook->jupyterlab-git) (0.1.8)\n",
      "Installing collected packages: jupyterlab-git\n",
      "  Attempting uninstall: jupyterlab-git\n",
      "    Found existing installation: jupyterlab-git 0.4.4\n",
      "    Uninstalling jupyterlab-git-0.4.4:\n",
      "      Successfully uninstalled jupyterlab-git-0.4.4\n",
      "Successfully installed jupyterlab-git-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade jupyterlab-git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-68ccd730df68>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-68ccd730df68>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter serverextension enable --py juoyterlab_git\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter serverextension enable --py juoyterlab_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter_contrib_nbextensions\n",
      "  Downloading jupyter_contrib_nbextensions-0.5.1-py2.py3-none-any.whl (20.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-latex-envs>=1.3.8\n",
      "  Downloading jupyter_latex_envs-1.4.6.tar.gz (861 kB)\n",
      "\u001b[K     |████████████████████████████████| 861 kB 32.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-nbextensions-configurator>=0.4.0\n",
      "  Downloading jupyter_nbextensions_configurator-0.4.1.tar.gz (479 kB)\n",
      "\u001b[K     |████████████████████████████████| 479 kB 29.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lxml in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (4.5.0)\n",
      "Requirement already satisfied: notebook>=4.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (6.0.3)\n",
      "Requirement already satisfied: tornado in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (6.0.3)\n",
      "Requirement already satisfied: nbconvert>=4.2 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (5.6.1)\n",
      "Requirement already satisfied: pyyaml in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (5.3)\n",
      "Collecting jupyter-highlight-selected-word>=0.1.1\n",
      "  Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: traitlets>=4.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (4.3.3)\n",
      "Collecting jupyter-contrib-core>=0.3.3\n",
      "  Downloading jupyter_contrib_core-0.3.3-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: jupyter-core in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (4.6.1)\n",
      "Requirement already satisfied: ipython-genutils in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter_contrib_nbextensions) (0.2.0)\n",
      "Requirement already satisfied: ipython in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (7.12.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (18.1.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (0.8.3)\n",
      "Requirement already satisfied: nbformat in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (5.0.4)\n",
      "Requirement already satisfied: Send2Trash in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (1.5.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (5.3.4)\n",
      "Requirement already satisfied: ipykernel in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (5.1.4)\n",
      "Requirement already satisfied: prometheus-client in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (0.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.0->jupyter_contrib_nbextensions) (2.11.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (0.3)\n",
      "Requirement already satisfied: testpath in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (0.4.4)\n",
      "Requirement already satisfied: pygments in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (2.5.2)\n",
      "Requirement already satisfied: defusedxml in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (0.8.4)\n",
      "Requirement already satisfied: bleach in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbconvert>=4.2->jupyter_contrib_nbextensions) (3.1.0)\n",
      "Requirement already satisfied: decorator in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.1->jupyter_contrib_nbextensions) (4.4.1)\n",
      "Requirement already satisfied: six in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.1->jupyter_contrib_nbextensions) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter-contrib-core>=0.3.3->jupyter_contrib_nbextensions) (46.0.0.post20200309)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.14.1)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.1.0)\n",
      "Requirement already satisfied: backcall in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (3.0.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from nbformat->notebook>=4.0->jupyter_contrib_nbextensions) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jupyter-client>=5.3.4->notebook>=4.0->jupyter_contrib_nbextensions) (2.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jinja2->notebook>=4.0->jupyter_contrib_nbextensions) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert>=4.2->jupyter_contrib_nbextensions) (0.5.1)\n",
      "Requirement already satisfied: parso>=0.5.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.5.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-latex-envs>=1.3.8->jupyter_contrib_nbextensions) (0.1.8)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0->jupyter_contrib_nbextensions) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0->jupyter_contrib_nbextensions) (0.15.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0->jupyter_contrib_nbextensions) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/Cho/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0->jupyter_contrib_nbextensions) (2.2.0)\n",
      "Building wheels for collected packages: jupyter-latex-envs, jupyter-nbextensions-configurator\n",
      "  Building wheel for jupyter-latex-envs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter-latex-envs: filename=jupyter_latex_envs-1.4.6-py2.py3-none-any.whl size=963395 sha256=46935ed3c31c5bb6073961cb50f949d3dcaceb1c6a79da44cc808498e738a74b\n",
      "  Stored in directory: /Users/Cho/Library/Caches/pip/wheels/a0/95/26/4cf34fb92765c95fb7851fd447511594bcc3a50e504bd09af9\n",
      "  Building wheel for jupyter-nbextensions-configurator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter-nbextensions-configurator: filename=jupyter_nbextensions_configurator-0.4.1-py2.py3-none-any.whl size=465825 sha256=46d552683b6855b729c09cbba3cc035cd11ca779bb03df4bde53b62fdba86b06\n",
      "  Stored in directory: /Users/Cho/Library/Caches/pip/wheels/8d/c4/b5/e4b61f624036f83566580d61f24af7b73180b1361ee1ab3722\n",
      "Successfully built jupyter-latex-envs jupyter-nbextensions-configurator\n",
      "Installing collected packages: jupyter-latex-envs, jupyter-contrib-core, jupyter-nbextensions-configurator, jupyter-highlight-selected-word, jupyter-contrib-nbextensions\n",
      "Successfully installed jupyter-contrib-core-0.3.3 jupyter-contrib-nbextensions-0.5.1 jupyter-highlight-selected-word-0.2.0 jupyter-latex-envs-1.4.6 jupyter-nbextensions-configurator-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-9683ae3d70f1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-9683ae3d70f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter serverextension list\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter serverextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-7a1db07b31e6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7a1db07b31e6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter serverextension enable --py jupyterlab_git --sys-prefix\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter serverextension enable --py jupyterlab_git --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
